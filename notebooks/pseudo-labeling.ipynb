{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pseudo-Labeling Flow",
   "id": "a48ee7ad8fc90e2a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This notebook implements an automated pseudo-labeling pipeline designed to streamline the annotation process for object detection and instance segmentation tasks. The tool iteratively improves model performance by using an initial model trained on a small set of manually annotated data to generate labels on new images, which can then be refined and used to retrain progressively better models.\n",
    "\n",
    "**A \"flow\" represents a complete pseudo labeling run with specific configuration settings (model type, initial dataset size, correction strategy), while \"iterations\" are the individual training cycles within each flow where new data is added and the model is retrained.**\n",
    "\n",
    "The features within this notebook include:\n",
    "- **Automated Pipeline**: Complete workflow from data preparation to model training\n",
    "- **Database Logging**: Database tracking for all iterations\n",
    "- **CVAT Integration**: For viewing and adjusting annotations\n",
    "- **Flexible Configuration**: Supports different model architectures and training settings\n",
    "- **Status Monitoring**: Real-time pipeline status and progress tracking\n"
   ],
   "id": "4363b46de49c818c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "59d550d53f7c2f2d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T14:21:42.106986Z",
     "start_time": "2025-06-13T14:21:40.872038Z"
    }
   },
   "cell_type": "code",
   "source": "from pseudo_labeling import PseudoLabelingPipeline",
   "id": "bbc3cfd3336091f4",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Global Initalizers\n",
    "Configure the pipeline with your project-specific settings:\n"
   ],
   "id": "e6cb8c06c2f22a57"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T14:22:50.674136Z",
     "start_time": "2025-06-13T14:22:49.954966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pipeline = PseudoLabelingPipeline(\n",
    "    project_name=\"daniel-osman---streamlining-annotation-bootstrapping/testing\",\n",
    "    main_dataset_name=\"full-data:0\", #input only\n",
    "    initial_annotated_dataset_name=\"initial-annotations:0\",\n",
    "    validation_dataset=\"val:0\",\n",
    "    sample_size_per_iter=150,\n",
    "    current_flow = 0,\n",
    "    min_confidence=0.5,\n",
    "    local_path='/Users/daniel/Documents/2025 BEP - VBTI Data/testing',\n",
    "    cvat_project_id=88,\n",
    "    db_path=\"pseudo_labeling_metadata.db\"\n",
    ")\n",
    "\n",
    "print(\"Pipeline initialized\")\n",
    "\n"
   ],
   "id": "e9dc56f69181b53c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-06-13 16:22:50.207\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36monedl._local_store.datasets\u001B[0m:\u001B[36mpull\u001B[0m:\u001B[36m838\u001B[0m - \u001B[1mPulling dataset full-data:0 from remote='daniel-osman---streamlining-annotation-bootstrapping/testing' with pull_policy=missing.\u001B[0m\n",
      "\u001B[32m2025-06-13 16:22:50.212\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36monedl._local_store.datasets\u001B[0m:\u001B[36mpull\u001B[0m:\u001B[36m858\u001B[0m - \u001B[1mDataset full-data:0 already exists in local store. Skipping\u001B[0m\n",
      "\u001B[32m2025-06-13 16:22:50.228\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36monedl._local_store.datasets\u001B[0m:\u001B[36mpull\u001B[0m:\u001B[36m838\u001B[0m - \u001B[1mPulling dataset initial-annotations:0 from remote='daniel-osman---streamlining-annotation-bootstrapping/testing' with pull_policy=missing.\u001B[0m\n",
      "\u001B[32m2025-06-13 16:22:50.230\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36monedl._local_store.datasets\u001B[0m:\u001B[36mpull\u001B[0m:\u001B[36m858\u001B[0m - \u001B[1mDataset initial-annotations:0 already exists in local store. Skipping\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "GLOBAL INITIALIZATIONS INITIALIZED\n",
      "============================================================\n",
      "Project: daniel-osman---streamlining-annotation-bootstrapping/testing\n",
      "Main dataset: full-data:0\n",
      "Initial annotated dataset: initial-annotations:0\n",
      "Sample size per iteration: 150\n",
      "Selected flow: f0\n",
      "Initial annotated dataset contains: 50 samples\n",
      "Creating new flow f0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-06-13 16:22:50.653\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36monedl._local_store.datasets\u001B[0m:\u001B[36mresolve_latest_version\u001B[0m:\u001B[36m582\u001B[0m - \u001B[1mResolved latest version of dataset train-f0 to 2 with remote='daniel-osman---streamlining-annotation-bootstrapping/testing'.\u001B[0m\n",
      "\u001B[32m2025-06-13 16:22:50.654\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36monedl._local_store.datasets\u001B[0m:\u001B[36mload\u001B[0m:\u001B[36m375\u001B[0m - \u001B[1mResolved latest version of dataset train-f0 to 2.\u001B[0m\n",
      "\u001B[32m2025-06-13 16:22:50.654\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36monedl._local_store.datasets\u001B[0m:\u001B[36mpull\u001B[0m:\u001B[36m838\u001B[0m - \u001B[1mPulling dataset train-f0:2 from remote='daniel-osman---streamlining-annotation-bootstrapping/testing' with pull_policy=missing.\u001B[0m\n",
      "\u001B[32m2025-06-13 16:22:50.656\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36monedl._local_store.datasets\u001B[0m:\u001B[36mpull\u001B[0m:\u001B[36m858\u001B[0m - \u001B[1mDataset train-f0:2 already exists in local store. Skipping\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset train-f0 already exists - skipping creation\n",
      "Flow f0 initialized with 50 initial samples\n",
      "Ready for iteration 0\n",
      "============================================================\n",
      "Pipeline initialized\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Training Config\n",
    "Set up your model training parameters interactively:\n"
   ],
   "id": "34c21f427b8edc65"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T14:24:22.524164Z",
     "start_time": "2025-06-13T14:24:22.517227Z"
    }
   },
   "cell_type": "code",
   "source": "train_cfg = pipeline.setup_training_config()\n",
   "id": "83c2514d8a26f4fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAINING CONFIGURATION SETUP ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Dropdown(description='Model Type:', options=(('FasterRCNNConfig (Object Detection)', 'FasterRCN…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3dc612b9c55b4a3ebe9e5a629dda30c0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "45938baed4f024d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# (1) Initial Flow, Training, and Evaluation Setup\n",
    "\n",
    "This step initiates the current flow and establishes the baseline model using your initial annotated dataset.\n",
    "1. Loads the initial annotated dataset.\n",
    "2. Created training set for the current flow.\n",
    "3. Trains the first baseline model (iteration 0) for the specified flow.\n",
    "4. Evaluates Model\n",
    "5. Logs Metadata (Only variables generated throughout the process of the pipeline are 'predicted_dataset_name', 'model_uid', 'evaluation_uid', 'evaluation_info')\n",
    "\n",
    "⚠️ ATTENTION: Skip this section if your current flow already exists and if you already have a baseline model"
   ],
   "id": "97d036474ce1b3e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T14:24:37.412895Z",
     "start_time": "2025-06-13T14:24:37.410402Z"
    }
   },
   "cell_type": "code",
   "source": "pipeline.get_pipeline_status()",
   "id": "d4389e61995bb67b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PIPELINE STATUS REPORT\n",
      "==================================================\n",
      "Flow ID: f0\n",
      "Current Iteration: 0\n",
      "Training Dataset: train-f0\n",
      "Current Model UID: None\n",
      "Training Configuration: {'model_type': 'FasterRCNNConfig', 'task_type': 'object_detection', 'backbone': <FasterRCNNBackbone.REGNET_GF4_0: 'REGNET_GF4_0'>, 'epochs': 1, 'batch_size': 6}\n",
      "Database Path: pseudo_labeling_metadata.db\n",
      "Sample Size Per Iteration: 150\n",
      "Minimum Confidence Threshold: 0.5\n",
      "\n",
      "RECENT ITERATIONS:\n",
      "==================================================\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1.1 Train Initial Model and Evaluate on Validation Set\n",
    "Train the baseline model on your initial annotated dataset.\n",
    "Evaluate the initial model performance on the validation dataset.\n",
    "\n",
    "\n"
   ],
   "id": "711f8bb04544ab75"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T14:25:44.557259Z",
     "start_time": "2025-06-13T14:24:42.574802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pipeline.train_model()\n",
    "pipeline.evaluate_model()"
   ],
   "id": "2fac8063b9a4b09a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-06-13 16:24:44.182\u001B[0m | \u001B[33m\u001B[1mWARNING \u001B[0m | \u001B[36monedl.zoo.mmlabs.mmdetection._augmentation\u001B[0m:\u001B[36mset_num_epochs\u001B[0m:\u001B[36m216\u001B[0m - \u001B[33m\u001B[1mTurning off second stage epoch, because it is bigger than number of epochs\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training FasterRCNNConfig on dataset: initial-annotations:0\n",
      "Configuration: 1 epochs, batch size 6\n",
      "Backbone: REGNET_GF4_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-06-13 16:24:45.627\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36monedl.client.operations.clients._common\u001B[0m:\u001B[36mcreate_event_stream\u001B[0m:\u001B[36m79\u001B[0m - \u001B[1mSubscribing to job events...\u001B[0m\n",
      "\u001B[32m2025-06-13 16:24:45.629\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36monedl.client.operations.clients._common\u001B[0m:\u001B[36mcreate_event_stream\u001B[0m:\u001B[36m80\u001B[0m - \u001B[1mJob internal-sharp-0 in WAITING state\u001B[0m\n",
      "\u001B[32m2025-06-13 16:24:46.879\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36monedl.client.operations.clients._common\u001B[0m:\u001B[36mcreate_event_stream\u001B[0m:\u001B[36m84\u001B[0m - \u001B[1mJob internal-sharp-0 in RUNNING state\u001B[0m\n",
      "\u001B[32m2025-06-13 16:25:44.542\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36monedl.client.operations.clients._common\u001B[0m:\u001B[36mcreate_event_stream\u001B[0m:\u001B[36m84\u001B[0m - \u001B[1mJob internal-sharp-0 in DONE state\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job submitted\n",
      "Model UID: internal-sharp-0\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T14:38:25.180152Z",
     "start_time": "2025-06-13T14:25:54.226561Z"
    }
   },
   "cell_type": "code",
   "source": "pipeline.evaluate_model()",
   "id": "43b17ed74be634e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating internal-sharp-0 on val:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-06-13 16:25:56.486\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36monedl.client.operations.clients._common\u001B[0m:\u001B[36mcreate_event_stream\u001B[0m:\u001B[36m79\u001B[0m - \u001B[1mSubscribing to job events...\u001B[0m\n",
      "\u001B[32m2025-06-13 16:25:56.487\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36monedl.client.operations.clients._common\u001B[0m:\u001B[36mcreate_event_stream\u001B[0m:\u001B[36m80\u001B[0m - \u001B[1mJob electric-sap-0 in WAITING state\u001B[0m\n",
      "\u001B[32m2025-06-13 16:25:57.680\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36monedl.client.operations.clients._common\u001B[0m:\u001B[36mcreate_event_stream\u001B[0m:\u001B[36m84\u001B[0m - \u001B[1mJob electric-sap-0 in RUNNING state\u001B[0m\n",
      "\u001B[32m2025-06-13 16:25:57.690\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36monedl.client.operations.clients._common\u001B[0m:\u001B[36mcreate_event_stream\u001B[0m:\u001B[36m84\u001B[0m - \u001B[1mJob electric-sap-0 in RUNNING state\u001B[0m\n",
      "\u001B[32m2025-06-13 16:25:57.693\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36monedl.client.operations.clients._common\u001B[0m:\u001B[36mcreate_event_stream\u001B[0m:\u001B[36m84\u001B[0m - \u001B[1mJob electric-sap-0 in RUNNING state\u001B[0m\n",
      "\u001B[32m2025-06-13 16:38:22.773\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36monedl.client.operations.clients._common\u001B[0m:\u001B[36mcreate_event_stream\u001B[0m:\u001B[36m84\u001B[0m - \u001B[1mJob electric-sap-0 in DONE state\u001B[0m\n",
      "                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete\n",
      "Report URL: https://21e007818fa1dd0840eac0d6d59ba986.eu.r2.cloudflarestorage.com/onedl-data/daniel-osman---streamlining-annotation-bootstrapping/testing/-/48bec55c660bab448bc4abb9903fa1ce.html?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=bb17714b86b2e84a836c55404335cef8%2F20250613%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250613T143825Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=2631e8c634b067027746b2620966be04cf76612d6f9142608ab532fa1cacfcc4\n",
      "Metrics: {\"mAP50\": 0.0, \"mAP75\": 0.0, \"mAP_all\": 0.0, \"fn_count\": 210, \"fp_count\": 0, \"tp_count\": 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1.2 Log\n",
    "Save all metadata for the initial training iteration to the database.\n"
   ],
   "id": "b9a7244aa3cfd292"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T14:42:36.412777Z",
     "start_time": "2025-06-13T14:42:36.371397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pipeline.log_iteration_0()\n",
    "print(\"Initial model training and evaluation complete, Current status:\")\n",
    "pipeline.get_pipeline_status()"
   ],
   "id": "89bef19e5c8088c0",
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "20 values for 21 columns",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mOperationalError\u001B[39m                          Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mpipeline\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlog_iteration_0\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      2\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mInitial model training and evaluation complete, Current status:\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m      3\u001B[39m pipeline.get_pipeline_status()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/VBTI - Pseudo.Labeling/pseudo_labeling.py:1595\u001B[39m, in \u001B[36mPseudoLabelingPipeline.log_iteration_0\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1593\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mlog_iteration_0\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m   1594\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Log iteration 0 to the database (legacy method for compatibility).\"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1595\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdb\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlog_iteration_0\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1596\u001B[39m \u001B[43m        \u001B[49m\u001B[43mflow_id\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mflow_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1597\u001B[39m \u001B[43m        \u001B[49m\u001B[43miteration\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1598\u001B[39m \u001B[43m        \u001B[49m\u001B[43mnum_gt_images\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mn_initial_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1599\u001B[39m \u001B[43m        \u001B[49m\u001B[43mnum_gt_images_added\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mn_initial_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1600\u001B[39m \u001B[43m        \u001B[49m\u001B[43mnum_pseudo_images\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1601\u001B[39m \u001B[43m        \u001B[49m\u001B[43mnum_pseudo_images_added\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1602\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtotal_train_size\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mn_initial_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1603\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtrain_dataset_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1604\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpseudo_input_dataset_name\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1605\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpseudo_output_dataset_name\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1606\u001B[39m \u001B[43m        \u001B[49m\u001B[43minference_model_uid\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1607\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodel_uid\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel_uid\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1608\u001B[39m \u001B[43m        \u001B[49m\u001B[43mevaluation_uid\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mevaluation_uid\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1609\u001B[39m \u001B[43m        \u001B[49m\u001B[43mevaluation_info\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mevaluation_info_str\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1610\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmanual_correction\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1611\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcvat_project_id\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcvat_project_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1612\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmain_dataset\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmain_dataset_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1613\u001B[39m \u001B[43m        \u001B[49m\u001B[43mvalidation_dataset\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mvalidation_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1614\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrain_cfg\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtrain_cfg\u001B[49m\n\u001B[32m   1615\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1617\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mIteration 0 logged for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.flow_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/VBTI - Pseudo.Labeling/pseudo_labeling.py:174\u001B[39m, in \u001B[36mDatabaseManager.log_iteration_0\u001B[39m\u001B[34m(self, **kwargs)\u001B[39m\n\u001B[32m    171\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Log iteration 0 to the database (legacy method for compatibility).\"\"\"\u001B[39;00m\n\u001B[32m    172\u001B[39m train_cfg_str = \u001B[38;5;28mstr\u001B[39m(kwargs.get(\u001B[33m'\u001B[39m\u001B[33mtrain_cfg\u001B[39m\u001B[33m'\u001B[39m)) \u001B[38;5;28;01mif\u001B[39;00m kwargs.get(\u001B[33m'\u001B[39m\u001B[33mtrain_cfg\u001B[39m\u001B[33m'\u001B[39m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m174\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcursor\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'''\u001B[39;49m\n\u001B[32m    175\u001B[39m \u001B[33;43m    INSERT OR REPLACE INTO iteration_metadata (\u001B[39;49m\n\u001B[32m    176\u001B[39m \u001B[33;43m        flow_id, iteration, status,\u001B[39;49m\n\u001B[32m    177\u001B[39m \u001B[33;43m        num_gt_images, num_gt_images_added,\u001B[39;49m\n\u001B[32m    178\u001B[39m \u001B[33;43m        num_pseudo_images, num_pseudo_images_added,\u001B[39;49m\n\u001B[32m    179\u001B[39m \u001B[33;43m        total_train_size,\u001B[39;49m\n\u001B[32m    180\u001B[39m \u001B[33;43m        main_dataset, validation_set, train_dataset,\u001B[39;49m\n\u001B[32m    181\u001B[39m \u001B[33;43m        pseudo_input_dataset_name, pseudo_output_dataset_name,\u001B[39;49m\n\u001B[32m    182\u001B[39m \u001B[33;43m        inference_model_uid, model_uid, evaluation_uid, evaluation_info,\u001B[39;49m\n\u001B[32m    183\u001B[39m \u001B[33;43m        manual_correction, cvat_project_id, train_cfg,\u001B[39;49m\n\u001B[32m    184\u001B[39m \u001B[33;43m        completed_timestamp\u001B[39;49m\n\u001B[32m    185\u001B[39m \u001B[33;43m    ) VALUES (?, ?, \u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mCOMPLETED\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[33;43m, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\u001B[39;49m\n\u001B[32m    186\u001B[39m \u001B[33;43m\u001B[39;49m\u001B[33;43m'''\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    187\u001B[39m \u001B[43m    \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mflow_id\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43miteration\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    188\u001B[39m \u001B[43m    \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mnum_gt_images\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mnum_gt_images_added\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    189\u001B[39m \u001B[43m    \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mnum_pseudo_images\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mnum_pseudo_images_added\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    190\u001B[39m \u001B[43m    \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mtotal_train_size\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    191\u001B[39m \u001B[43m    \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mmain_dataset\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mvalidation_dataset\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mtrain_dataset\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    192\u001B[39m \u001B[43m    \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mpseudo_input_dataset_name\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mpseudo_output_dataset_name\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    193\u001B[39m \u001B[43m    \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43minference_model_uid\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mmodel_uid\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mevaluation_uid\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mevaluation_info\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    194\u001B[39m \u001B[43m    \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mmanual_correction\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mcvat_project_id\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_cfg_str\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    195\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtime\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstrftime\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43m%\u001B[39;49m\u001B[33;43mY-\u001B[39;49m\u001B[33;43m%\u001B[39;49m\u001B[33;43mm-\u001B[39;49m\u001B[38;5;132;43;01m%d\u001B[39;49;00m\u001B[33;43m \u001B[39;49m\u001B[33;43m%\u001B[39;49m\u001B[33;43mH:\u001B[39;49m\u001B[33;43m%\u001B[39;49m\u001B[33;43mM:\u001B[39;49m\u001B[33;43m%\u001B[39;49m\u001B[33;43mS\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    196\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    197\u001B[39m \u001B[38;5;28mself\u001B[39m.conn.commit()\n",
      "\u001B[31mOperationalError\u001B[39m: 20 values for 21 columns"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# (2) Pseudo-Labeling Iteration Workflow\n",
    "\n",
    "This step executes a complete pseudo-labeling iteration cycle using the model from the previous iteration to generate labels on new data.\n",
    "1. Sets up the next iteration with correction strategy (manual or automated).\n",
    "2. Samples new unlabeled data from the full dataset.\n",
    "3. Runs inference using the previous iteration's model to generate pseudo-labels.\n",
    "4. Handles corrections based on strategy: exports to CVAT for manual corrections OR merges pseudo-labels directly.\n",
    "5. Trains updated model on expanded dataset (original + new data).\n",
    "6. Evaluates the updated model performance.\n",
    "7. Logs iteration metadata to track progress and results.\n",
    "\n",
    "**⚠️ ATTENTION: Set 'manual_corrections=True' for CVAT workflow with human review, or 'manual_corrections=False' for fully automated pseudo-labeling**\n"
   ],
   "id": "a448c0a08eb5e7f1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Local Initializer\n",
    "Configure the next iteration parameters"
   ],
   "id": "813231686bb6f992"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T13:11:10.111178Z",
     "start_time": "2025-06-13T13:11:10.108492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set manual_corrections=True for CVAT human review\n",
    "# Set manual_corrections=False for fully automated pseudo-labeling\n",
    "manual_corrections = False\n",
    "pipeline.setup_next_iteration(manual_corrections)\n"
   ],
   "id": "9a5fa58ccb1fd960",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "FLOW INITIALIZATION COMPLETE\n",
      "========================================\n",
      "Resuming flow_id: f0\n",
      "Current iteration: 1\n",
      "Manual corrections: False\n",
      "Sample size this iteration: 150\n",
      "GT added this iteration: 0\n",
      "Pseudo added this iteration: 150\n",
      "Total GT images after this step: 50\n",
      "Total pseudo-labeled images after this step: 150\n",
      "Total expected training set size: 200\n",
      "Train dataset name: train-f0\n",
      "Pseudo input dataset name: pseudo-iter1-f0\n",
      "Using initial annotations: initial-annotations:0\n",
      "Inference model UID: mad-omega-0\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.1 Sample New Data",
   "id": "5e11a14b96cfb09"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pipeline.sample_unseen_inputs()",
   "id": "7b5a6c0842156175",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.2 Generate Predictions/Pseudo-Labels\n",
   "id": "3ce8b829263e762f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#pipeline.run_inference()\n",
    "pipeline.set_predicted_dataset('demo-val')"
   ],
   "id": "7e63fae3319becfc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.3 CVAT Export",
   "id": "dc43711977711a65"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T11:51:08.734093Z",
     "start_time": "2025-06-12T11:50:53.849137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if pipeline.manual_corrections_global:\n",
    "    print(\"Manual corrections enabled - proceeding to CVAT export\")\n",
    "    pipeline.manually_correct_cvat()\n",
    "    print(\"After completing corrections in CVAT, manually update the predicted dataset and run the merge cell below\")\n",
    "else:\n",
    "    print(\"No Manual Correction, Proceed to merging the datasets\")\n"
   ],
   "id": "f8bc6bab0ca05bfa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual corrections enabled - proceeding to CVAT export\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[19]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m pipeline.manual_corrections_global:\n\u001B[32m      2\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mManual corrections enabled - proceeding to CVAT export\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m     \u001B[43mpipeline\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmanually_correct_cvat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      4\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mAfter completing corrections in CVAT, manually update the predicted dataset and run the merge cell below\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/VBTI - Pseudo.Labeling/core/pseudo_core.py:781\u001B[39m, in \u001B[36mPseudoLabelingPipeline.manually_correct_cvat\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    778\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[32m    780\u001B[39m \u001B[38;5;66;03m# Get user input\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m781\u001B[39m username = \u001B[38;5;28;43minput\u001B[39;49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mCVAT Username: \u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    782\u001B[39m password = \u001B[38;5;28minput\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mCVAT Password: \u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    783\u001B[39m project_name = \u001B[38;5;28minput\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mCVAT Project Name (default: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.flow_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m-project): \u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.flow_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m-project\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py:1282\u001B[39m, in \u001B[36mKernel.raw_input\u001B[39m\u001B[34m(self, prompt)\u001B[39m\n\u001B[32m   1280\u001B[39m     msg = \u001B[33m\"\u001B[39m\u001B[33mraw_input was called, but this frontend does not support input requests.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1281\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m StdinNotImplementedError(msg)\n\u001B[32m-> \u001B[39m\u001B[32m1282\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_input_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1283\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1284\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_parent_ident\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mshell\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1285\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mget_parent\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mshell\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1286\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpassword\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1287\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py:1325\u001B[39m, in \u001B[36mKernel._input_request\u001B[39m\u001B[34m(self, prompt, ident, parent, password)\u001B[39m\n\u001B[32m   1322\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[32m   1323\u001B[39m     \u001B[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001B[39;00m\n\u001B[32m   1324\u001B[39m     msg = \u001B[33m\"\u001B[39m\u001B[33mInterrupted by user\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1325\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1326\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[32m   1327\u001B[39m     \u001B[38;5;28mself\u001B[39m.log.warning(\u001B[33m\"\u001B[39m\u001B[33mInvalid Message:\u001B[39m\u001B[33m\"\u001B[39m, exc_info=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: Interrupted by user"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.4. Merge Data\n",
    "This cell merges the dataset with current training set. If **manual_correction = True**, then corrected annotations will be exported and merged.\n"
   ],
   "id": "209f3870a60460dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pipeline.merge_pseudo_labels()",
   "id": "3a2c98c6bda8e396",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.5 Train Updated Model\n",
    "Train a new model on the expanded training set"
   ],
   "id": "b501662afac7aa99"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pipeline.train_model()",
   "id": "7e822708055ad554",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.6 Evaluate Performance",
   "id": "7a4feb9510ede0a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pipeline.evaluate_model()",
   "id": "daa83206d911d917",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.7 Log Iteration  Results",
   "id": "1357a4f3c2cd78ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pipeline.log_iteration()\n",
    "print(\"Iteration Complete\")\n",
    "pipeline.get_pipeline_status()"
   ],
   "id": "843955a711b93b5f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Additional Runs\n",
    "To run additional iterations, repeat Section 2 after logging. For creating a new flow, go back to Section 1, update the current_flow and go again.\n"
   ],
   "id": "bcb41c36fe5ccd64"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
